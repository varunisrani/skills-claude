# AI & LLM Skills

This category contains skills for AI application development, LLM integration, RAG systems, and prompt engineering.

## Skills in This Category

### `claude-agent-sdk`
Building Claude SDK agents with specialized capabilities.

**Use when:**
- Building Claude SDK agents
- Creating AI agents with Claude
- Integrating Claude into applications

**Key topics:**
- Claude SDK fundamentals
- Agent architecture
- SDK integration patterns

---

### `claude-sdk-agent-generator`
Generate complete Claude SDK agents with prompt templates and configuration.

**Use when:**
- Creating new Claude agents quickly
- Generating agent templates
- Setting up agent configurations

**Key topics:**
- Agent generation
- Prompt templates
- Agent configuration
- Code generation

---

### `langchain-architecture`
Design LLM applications using the LangChain framework with agents, memory, and tool integration patterns.

**Use when:**
- Building LangChain applications
- Implementing AI agents
- Creating complex LLM workflows

**Key topics:**
- LangChain framework
- Agent patterns
- Memory management
- Tool integration
- LLM workflows

---

### `llm-evaluation`
Implement comprehensive evaluation strategies for LLM applications using automated metrics, human feedback, and benchmarking.

**Use when:**
- Testing LLM performance
- Measuring AI application quality
- Establishing evaluation frameworks

**Key topics:**
- Automated metrics
- Human feedback loops
- Benchmarking
- Quality assurance for AI

---

### `mcp-builder`
Guide for creating high-quality MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools.

**Use when:**
- Building MCP servers
- Integrating external APIs with LLMs
- Creating LLM tools
- Working with FastMCP (Python) or MCP SDK (Node/TypeScript)

**Key topics:**
- Model Context Protocol
- MCP server design
- Tool integration
- FastMCP and MCP SDK

---

### `prompt-engineering-patterns`
Master advanced prompt engineering techniques to maximize LLM performance, reliability, and controllability in production.

**Use when:**
- Optimizing prompts
- Improving LLM outputs
- Designing production prompt templates
- Debugging LLM behavior

**Key topics:**
- Prompt design patterns
- LLM optimization
- Production-ready prompts
- Reliability techniques

---

### `rag-implementation`
Build Retrieval-Augmented Generation (RAG) systems for LLM applications with vector databases and semantic search.

**Use when:**
- Implementing knowledge-grounded AI
- Building document Q&A systems
- Integrating LLMs with external knowledge bases

**Key topics:**
- RAG architecture
- Vector databases
- Semantic search
- Knowledge retrieval
- Document processing

---

## Common Use Cases

### Building a RAG Application
Combine these skills:
1. `rag-implementation` - RAG architecture
2. `prompt-engineering-patterns` - Prompt optimization
3. `llm-evaluation` - Testing and evaluation
4. `mcp-builder` - External tool integration (if needed)

### Creating LangChain Application
Use:
1. `langchain-architecture` - Framework patterns
2. `prompt-engineering-patterns` - Prompt design
3. `llm-evaluation` - Quality assurance

### Building an MCP Server
Use:
1. `mcp-builder` - Server implementation
2. `prompt-engineering-patterns` - Tool integration prompts
3. Consider also: `fastapi-templates` or `nodejs-backend-patterns` from Backend Development

### Optimizing LLM Performance
Combine:
1. `prompt-engineering-patterns` - Prompt optimization
2. `llm-evaluation` - Performance measurement
3. `rag-implementation` - Knowledge enhancement (if applicable)

---

## Related Categories

- **Backend Development** - For API integration and backend services
- **Architecture & Design** - For AI system architecture
- **Code Quality & Testing** - For testing AI applications

---

[Back to Main README](../README.md) | [Quick Reference](../QUICK_REFERENCE.md) | [Usage Guide](../USAGE_GUIDE.md)
